{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16f9fab9",
   "metadata": {},
   "source": [
    "# TITLE : MODELS OF DENSITY FROM COMPOSITIONAL DATA MWC7+  TEMP PRESSURE USING MACHINE LEARNING ALGORITHM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed97750",
   "metadata": {},
   "source": [
    "OBJECTIVE : TRINING OF MODELS FOR FUTURE SELECTION FOR PREDICTION OF DENSITY USING WIDE RANGE OF COMPOSITION DATA.\n",
    "\n",
    "THIS FILE AUTOMATICALLY FIT MODELS AND STORE MODELS AT GIVEN PATH \n",
    "\n",
    "IF REVIEWER WANT TO CHECK SIMILLAR MODELS USED TO PREDICT TEST OR NOT WHICH TRAINED HERE THAN IN MODEL VALIDATION FILE OPTIMIZED PARAMETER CAN BE CKECKED WHICH AVOID RETRAINING WHICH TAKE A LOT TIME AS WELL AS TO CHECK DATA TRAIN AND TEST ALREADY SEPRATED AND STAROED INTO DATASOURCE FROM PREPROCESSING FILE SAME DATA USED HERE WHICH VERIFIED BY CHEKING EXCEL FILES \n",
    "\n",
    "\n",
    "ALGORITHM APPLIED : LINEAR REGRESSION, SUPPORT VECTOR MACHINE, KNN, RANDOM FOREST, DECISION TREE, XGB , ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1540939f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-1ef187d9cf9b>:33: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import RandomSearch\n"
     ]
    }
   ],
   "source": [
    "#DATA EXTRACTION, MANIPULATION, VIZULIZATION LIBRARY\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "#STATISTICAL TOOLS LIBRARY\n",
    "import scipy.stats as stat\n",
    "import pylab \n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "#DATA FETURES OPERATION LIBRARY\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#MODELING LIBRARY\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor, export_graphviz\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "#MODELLING OF DEEP LEARNING MODEL\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "\n",
    "#MODEL EVALUATION LIBRARY\n",
    "from sklearn.metrics import mean_squared_error , mean_absolute_error\n",
    "\n",
    "\n",
    "#Model saving\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5bbfaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\STUDY DRIVE\\\\DENSITY PAPER THESIS\\\\DENSITY COMPOSITION\\\\MODEL 3\\\\DATASOURCE\\\\\"\n",
    "file_name = \"TRAIN.csv\"\n",
    "model_path = \"C:\\\\STUDY DRIVE\\\\DENSITY PAPER THESIS\\\\DENSITY COMPOSITION\\\\MODEL 3\\\\MODELS\\\\\"\n",
    "\n",
    "export_data_path = \"C:\\\\STUDY DRIVE\\\\DENSITY PAPER THESIS\\\\DENSITY COMPOSITION\\\\MODEL 3\\\\EXPORTED DATA\\\\\"\n",
    "\n",
    "train = pd.read_csv(path+file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af82db33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>H2S</th>\n",
       "      <th>N2</th>\n",
       "      <th>CO2</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3-C6</th>\n",
       "      <th>C7+</th>\n",
       "      <th>MWC7+</th>\n",
       "      <th>Temp</th>\n",
       "      <th>P</th>\n",
       "      <th>Density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.00960</td>\n",
       "      <td>0.32030</td>\n",
       "      <td>0.034900</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>0.61390</td>\n",
       "      <td>283.486905</td>\n",
       "      <td>333.15</td>\n",
       "      <td>244.163133</td>\n",
       "      <td>867.630061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.01380</td>\n",
       "      <td>0.36170</td>\n",
       "      <td>0.075732</td>\n",
       "      <td>0.204968</td>\n",
       "      <td>0.33350</td>\n",
       "      <td>195.711574</td>\n",
       "      <td>427.60</td>\n",
       "      <td>194.655432</td>\n",
       "      <td>569.556880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.01940</td>\n",
       "      <td>0.65990</td>\n",
       "      <td>0.086900</td>\n",
       "      <td>0.155800</td>\n",
       "      <td>0.06590</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>366.70</td>\n",
       "      <td>413.800000</td>\n",
       "      <td>391.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.00860</td>\n",
       "      <td>0.18062</td>\n",
       "      <td>0.059914</td>\n",
       "      <td>0.219106</td>\n",
       "      <td>0.52525</td>\n",
       "      <td>233.365889</td>\n",
       "      <td>323.20</td>\n",
       "      <td>58.104568</td>\n",
       "      <td>727.655316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00355</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.02548</td>\n",
       "      <td>0.47244</td>\n",
       "      <td>0.069370</td>\n",
       "      <td>0.153400</td>\n",
       "      <td>0.27176</td>\n",
       "      <td>214.209832</td>\n",
       "      <td>394.25</td>\n",
       "      <td>276.000000</td>\n",
       "      <td>606.061000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       H2S      N2      CO2       C1        C2     C3-C6      C7+       MWC7+  \\\n",
       "0  0.00000  0.0002  0.00960  0.32030  0.034900  0.021200  0.61390  283.486905   \n",
       "1  0.00000  0.0103  0.01380  0.36170  0.075732  0.204968  0.33350  195.711574   \n",
       "2  0.00000  0.0121  0.01940  0.65990  0.086900  0.155800  0.06590  140.000000   \n",
       "3  0.00000  0.0065  0.00860  0.18062  0.059914  0.219106  0.52525  233.365889   \n",
       "4  0.00355  0.0040  0.02548  0.47244  0.069370  0.153400  0.27176  214.209832   \n",
       "\n",
       "     Temp           P     Density  \n",
       "0  333.15  244.163133  867.630061  \n",
       "1  427.60  194.655432  569.556880  \n",
       "2  366.70  413.800000  391.400000  \n",
       "3  323.20   58.104568  727.655316  \n",
       "4  394.25  276.000000  606.061000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f22cc210",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(\"Density\",axis = 1)\n",
    "y_train = train.Density"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6979354e",
   "metadata": {},
   "source": [
    "                              #### Scalling Dataset ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65eac258",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a868c421",
   "metadata": {},
   "outputs": [],
   "source": [
    "#following model path follows for all models location\n",
    "scaler_file = 'scaler.sav'\n",
    "pickle.dump(scaler , open(model_path+scaler_file , \"wb\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec97328",
   "metadata": {},
   "source": [
    "##### .......................................................................................SectionBreak......................................................................................."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fd457a",
   "metadata": {},
   "source": [
    "## 1. Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94509d12",
   "metadata": {},
   "source": [
    "                              #### Calculate VIF for features ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da5c39f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIF = [variance_inflation_factor(x_train , i) for i in range(0,x_train.shape[1])]  #shape is indicating number of columns which is argument for VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aca55c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FEATURES</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H2S</td>\n",
       "      <td>71.367143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N2</td>\n",
       "      <td>29.795244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CO2</td>\n",
       "      <td>11.274044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C1</td>\n",
       "      <td>708.850791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C2</td>\n",
       "      <td>63.954005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C3-C6</td>\n",
       "      <td>88.763298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C7+</td>\n",
       "      <td>677.649821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MWC7+</td>\n",
       "      <td>5.929897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Temp</td>\n",
       "      <td>1.491827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>P</td>\n",
       "      <td>1.753342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  FEATURES         VIF\n",
       "0      H2S   71.367143\n",
       "1       N2   29.795244\n",
       "2      CO2   11.274044\n",
       "3       C1  708.850791\n",
       "4       C2   63.954005\n",
       "5    C3-C6   88.763298\n",
       "6      C7+  677.649821\n",
       "7    MWC7+    5.929897\n",
       "8     Temp    1.491827\n",
       "9        P    1.753342"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VIF_DataFrame = pd.DataFrame(VIF)\n",
    "VIF_DataFrame = VIF_DataFrame.rename({0:\"VIF\"} , axis = 1)\n",
    "VIF_DataFrame[\"FEATURES\"] = X_train.columns\n",
    "VIF_DataFrame = VIF_DataFrame[[\"FEATURES\" , \"VIF\"]]\n",
    "VIF_DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f544499",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIF_DataFrame.to_excel(export_data_path+\"VIF.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8d7d78",
   "metadata": {},
   "source": [
    "                              #### Model Fitting for linear regression ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a976edbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression = LinearRegression()\n",
    "linear_regression.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488e563a",
   "metadata": {},
   "source": [
    "                         #### Model Summary #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e59072f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_linear_summary = sm.add_constant(x_train, prepend=False)\n",
    "y_train_linear_summary = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93a63555",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_summary = sm.OLS(y_train_linear_summary ,  x_train_linear_summary).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "547ee538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Density</td>     <th>  R-squared:         </th> <td>   0.878</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.871</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   114.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 26 Feb 2022</td> <th>  Prob (F-statistic):</th> <td>6.04e-67</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:33:26</td>     <th>  Log-Likelihood:    </th> <td> -961.54</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   169</td>      <th>  AIC:               </th> <td>   1945.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   158</td>      <th>  BIC:               </th> <td>   1980.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    10</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>  -34.1240</td> <td>   48.098</td> <td>   -0.709</td> <td> 0.479</td> <td> -129.123</td> <td>   60.875</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -8.8762</td> <td>   31.078</td> <td>   -0.286</td> <td> 0.776</td> <td>  -70.258</td> <td>   52.506</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>  -10.3588</td> <td>   19.117</td> <td>   -0.542</td> <td> 0.589</td> <td>  -48.117</td> <td>   27.399</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td> -111.8624</td> <td>  151.586</td> <td>   -0.738</td> <td> 0.462</td> <td> -411.259</td> <td>  187.534</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>  -19.1084</td> <td>   45.532</td> <td>   -0.420</td> <td> 0.675</td> <td> -109.038</td> <td>   70.821</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>   21.0004</td> <td>   53.641</td> <td>    0.391</td> <td> 0.696</td> <td>  -84.946</td> <td>  126.947</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>   81.7360</td> <td>  148.212</td> <td>    0.551</td> <td> 0.582</td> <td> -210.997</td> <td>  374.469</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>  -28.4716</td> <td>   13.865</td> <td>   -2.054</td> <td> 0.042</td> <td>  -55.855</td> <td>   -1.088</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>  -51.5803</td> <td>    6.954</td> <td>   -7.417</td> <td> 0.000</td> <td>  -65.315</td> <td>  -37.845</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   59.3126</td> <td>    7.539</td> <td>    7.867</td> <td> 0.000</td> <td>   44.422</td> <td>   74.203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>  567.0905</td> <td>    5.694</td> <td>   99.603</td> <td> 0.000</td> <td>  555.845</td> <td>  578.336</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 4.381</td> <th>  Durbin-Watson:     </th> <td>   2.249</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.112</td> <th>  Jarque-Bera (JB):  </th> <td>   3.385</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.224</td> <th>  Prob(JB):          </th> <td>   0.184</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.470</td> <th>  Cond. No.          </th> <td>    71.8</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                Density   R-squared:                       0.878\n",
       "Model:                            OLS   Adj. R-squared:                  0.871\n",
       "Method:                 Least Squares   F-statistic:                     114.0\n",
       "Date:                Sat, 26 Feb 2022   Prob (F-statistic):           6.04e-67\n",
       "Time:                        16:33:26   Log-Likelihood:                -961.54\n",
       "No. Observations:                 169   AIC:                             1945.\n",
       "Df Residuals:                     158   BIC:                             1980.\n",
       "Df Model:                          10                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1           -34.1240     48.098     -0.709      0.479    -129.123      60.875\n",
       "x2            -8.8762     31.078     -0.286      0.776     -70.258      52.506\n",
       "x3           -10.3588     19.117     -0.542      0.589     -48.117      27.399\n",
       "x4          -111.8624    151.586     -0.738      0.462    -411.259     187.534\n",
       "x5           -19.1084     45.532     -0.420      0.675    -109.038      70.821\n",
       "x6            21.0004     53.641      0.391      0.696     -84.946     126.947\n",
       "x7            81.7360    148.212      0.551      0.582    -210.997     374.469\n",
       "x8           -28.4716     13.865     -2.054      0.042     -55.855      -1.088\n",
       "x9           -51.5803      6.954     -7.417      0.000     -65.315     -37.845\n",
       "x10           59.3126      7.539      7.867      0.000      44.422      74.203\n",
       "const        567.0905      5.694     99.603      0.000     555.845     578.336\n",
       "==============================================================================\n",
       "Omnibus:                        4.381   Durbin-Watson:                   2.249\n",
       "Prob(Omnibus):                  0.112   Jarque-Bera (JB):                3.385\n",
       "Skew:                          -0.224   Prob(JB):                        0.184\n",
       "Kurtosis:                       2.470   Cond. No.                         71.8\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_summary.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ba58d5",
   "metadata": {},
   "source": [
    "                                    #### Model Saving ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ea5db24",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_file = 'linear_model.sav'\n",
    "pickle.dump(linear_regression , open(model_path+linear_file , \"wb\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23ad114",
   "metadata": {},
   "source": [
    "## 2. SVR MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10b9e79",
   "metadata": {},
   "source": [
    "                              #### Model tuning for svr Regression ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc19298d",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_model = SVR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca54247a",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_para = {'C':range(4000,10000,100),'gamma':np.arange(0.000,0.002,0.0001)}\n",
    "svr_grid = GridSearchCV(svr_model,svr_para, cv = 5 , verbose=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4616eefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1200 candidates, totalling 6000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 528 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 5936 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done 6000 out of 6000 | elapsed:    5.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3,\n",
       "                           epsilon=0.1, gamma='scale', kernel='rbf',\n",
       "                           max_iter=-1, shrinking=True, tol=0.001,\n",
       "                           verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'C': range(4000, 10000, 100),\n",
       "                         'gamma': array([0.    , 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007,\n",
       "       0.0008, 0.0009, 0.001 , 0.0011, 0.0012, 0.0013, 0.0014, 0.0015,\n",
       "       0.0016, 0.0017, 0.0018, 0.0019])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d18015b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 9900, 'gamma': 0.0019}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e13728f",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_best_para = svr_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b01ed33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=9900, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=0.0019,\n",
       "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_regression = SVR( C = svr_best_para[\"C\"],\n",
    "                      gamma = svr_best_para[\"gamma\"])\n",
    "svr_regression.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c806ca9",
   "metadata": {},
   "source": [
    "                                          #### Model saveing #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0510d717",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_file = 'svr_model.sav'\n",
    "pickle.dump(svr_regression , open(model_path+svr_file , \"wb\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4a585c",
   "metadata": {},
   "source": [
    "## 3. Decision Tree Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8101f30b",
   "metadata": {},
   "source": [
    "                                          #### Model tuning #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "588eb01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f4011a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_para = {\n",
    "    'criterion': ['mse', 'mae'],\n",
    "    'max_depth' : range(2,32,1),\n",
    "    'min_samples_leaf' : range(1,7,1),\n",
    "    'min_samples_split': range(2,7,1),\n",
    "    'splitter' : ['best', 'random']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd9ee8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3600 candidates, totalling 18000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 2032 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done 17672 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done 18000 out of 18000 | elapsed:    8.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse',\n",
       "                                             max_depth=None, max_features=None,\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             presort='deprecated',\n",
       "                                             random_state=None,\n",
       "                                             splitter='best'),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'criterion': ['mse', 'mae'], 'max_depth': range(2, 32),\n",
       "                         'min_samples_leaf': range(1, 7),\n",
       "                         'min_samples_split': range(2, 7),\n",
       "                         'splitter': ['best', 'random']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_grid = GridSearchCV(estimator=dt_model,\n",
    "                     param_grid=dt_para,\n",
    "                     cv=5,\n",
    "                     n_jobs =-1,\n",
    "                     verbose=3)\n",
    "dt_grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5fb0f315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'mae',\n",
       " 'max_depth': 24,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 5,\n",
       " 'splitter': 'random'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fbbbc077",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_best_para = dt_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10ff71b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mae', max_depth=24,\n",
       "                      max_features=None, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=5,\n",
       "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                      random_state=0, splitter='random')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_regression = DecisionTreeRegressor(criterion = dt_best_para[\"criterion\"],\n",
    "                                      max_depth = dt_best_para[\"max_depth\"],\n",
    "                                      min_samples_leaf = dt_best_para[\"min_samples_leaf\"],\n",
    "                                      min_samples_split = dt_best_para[\"min_samples_split\"],\n",
    "                                      splitter = dt_best_para[\"splitter\"],\n",
    "                                      random_state = 0\n",
    "                                      )\n",
    "\n",
    "dt_regression.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48359c1d",
   "metadata": {},
   "source": [
    "                                          #### Model saveing #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "94985ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_path = 'C:\\\\STUDY DRIVE\\\\Mtech New\\\\DENSITY PREDICTION\\\\MODELS\\\\SATURATION PRESSURE PREDICTION SATURATION DATASET 2 PART 4 MODELS\\\\'\n",
    "dt_file = 'dt_model.sav'\n",
    "pickle.dump(dt_regression , open(model_path+dt_file , \"wb\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a483b4",
   "metadata": {},
   "source": [
    "## 4. Random forest Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44bf2ff",
   "metadata": {},
   "source": [
    "                                          #### Model parameter tuning #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1220c391",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd89700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_para = {\n",
    "    \"n_estimators\" : range(90,150,5),\n",
    "    'max_depth' : range(2,20,1),\n",
    "    'min_samples_leaf' : range(1,5,1),\n",
    "    'min_samples_split': range(2,5,1),\n",
    "    'max_features' : ['auto','log2']\n",
    "}\n",
    "\n",
    "rf_grid = GridSearchCV(estimator=rf_model,\n",
    "                           param_grid=rf_para,\n",
    "                           cv=5,\n",
    "                           n_jobs =-1,\n",
    "                           verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "127b0485",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5184 candidates, totalling 25920 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 208 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done 528 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=-1)]: Done 976 tasks      | elapsed:   26.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed:   42.3s\n",
      "[Parallel(n_jobs=-1)]: Done 2256 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3088 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4048 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 5136 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 6352 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 7696 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 9168 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 10768 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done 12496 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 14352 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done 16336 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=-1)]: Done 18448 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=-1)]: Done 20688 tasks      | elapsed: 10.9min\n",
      "[Parallel(n_jobs=-1)]: Done 23056 tasks      | elapsed: 12.2min\n",
      "[Parallel(n_jobs=-1)]: Done 25552 tasks      | elapsed: 13.7min\n",
      "[Parallel(n_jobs=-1)]: Done 25920 out of 25920 | elapsed: 13.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,\n",
       "                                             criterion='mse', max_depth=None,\n",
       "                                             max_features='auto',\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             max_samples=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             n_estimators=100, n_jobs=None,\n",
       "                                             oob_score=False, random_state=None,\n",
       "                                             verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'max_depth': range(2, 20),\n",
       "                         'max_features': ['auto', 'log2'],\n",
       "                         'min_samples_leaf': range(1, 5),\n",
       "                         'min_samples_split': range(2, 5),\n",
       "                         'n_estimators': range(90, 150, 5)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ccb62c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 15,\n",
       " 'max_features': 'log2',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 120}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "883a1566",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best_para = rf_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c8648f",
   "metadata": {},
   "source": [
    "                                          #### Model fiting with tuning #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "54b8ab5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=15, max_features='log2', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=120, n_jobs=None, oob_score=False,\n",
       "                      random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_regression = RandomForestRegressor(n_estimators = rf_best_para[\"n_estimators\"],\n",
    "                                      max_depth = rf_best_para[\"max_depth\"],\n",
    "                                      min_samples_leaf =rf_best_para[\"min_samples_leaf\"],\n",
    "                                      min_samples_split = rf_best_para[\"min_samples_split\"],\n",
    "                                      max_features = rf_best_para[\"max_features\"],\n",
    "                                      random_state = 0\n",
    "                                      )\n",
    "\n",
    "rf_regression.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2435ab",
   "metadata": {},
   "source": [
    "                                          #### Model Saving #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fc9c0930",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_file = 'rf_model.sav'\n",
    "pickle.dump(rf_regression , open(model_path+rf_file , \"wb\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7ef5e6",
   "metadata": {},
   "source": [
    "## 5. KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "90427214",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4294a5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_para = {\"n_neighbors\"  : range(2,11)}\n",
    "knn_grid = GridSearchCV(knn_model,knn_para, verbose=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2c8283e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  45 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=KNeighborsRegressor(algorithm='auto', leaf_size=30,\n",
       "                                           metric='minkowski',\n",
       "                                           metric_params=None, n_jobs=None,\n",
       "                                           n_neighbors=5, p=2,\n",
       "                                           weights='uniform'),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'n_neighbors': range(2, 11)}, pre_dispatch='2*n_jobs',\n",
       "             refit=True, return_train_score=False, scoring=None, verbose=3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "786fbbbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 3}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d7d26ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_best_para = knn_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2a5cff0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                    metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "                    weights='uniform')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_regression = KNeighborsRegressor( n_neighbors = knn_best_para[\"n_neighbors\"])\n",
    "\n",
    "knn_regression.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d766200",
   "metadata": {},
   "source": [
    "                                          #### Model Saving #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bb4419e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_file = 'knn_model.sav'\n",
    "pickle.dump(knn_regression , open(model_path+knn_file , \"wb\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a02bc62",
   "metadata": {},
   "source": [
    "## 6. XGB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "db23419b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "15b030c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_para={\n",
    "   \n",
    "    'learning_rate': np.arange(0.1,0.2,0.04),\n",
    "    'max_depth': range(2,10,1),\n",
    "    'n_estimators':range(90,150,10),\n",
    "    \"gamma\" : np.arange(0.1,0.5,0.3),\n",
    "    \"min_child_weight\": range(1,10,2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d68cb016",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_grid = GridSearchCV(xgb_model,xgb_para, cv = 5 , verbose=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f5cda953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1440 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done 496 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   19.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1136 tasks      | elapsed:   30.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1552 tasks      | elapsed:   39.3s\n",
      "[Parallel(n_jobs=-1)]: Done 2032 tasks      | elapsed:   52.5s\n",
      "[Parallel(n_jobs=-1)]: Done 2576 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 3856 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4592 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 5392 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 6256 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 7184 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 7200 out of 7200 | elapsed:  3.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None, gamma=None,\n",
       "                                    gpu_id=None, importance_type='gain',\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, max_delta_step=None,\n",
       "                                    max_depth=None, min_child_weight=None,\n",
       "                                    missing=nan, monotone_constraints=None,\n",
       "                                    n_estima...\n",
       "                                    reg_lambda=None, scale_pos_weight=None,\n",
       "                                    subsample=None, tree_method=None,\n",
       "                                    validate_parameters=None, verbosity=None),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'gamma': array([0.1, 0.4]),\n",
       "                         'learning_rate': array([0.1 , 0.14, 0.18]),\n",
       "                         'max_depth': range(2, 10),\n",
       "                         'min_child_weight': range(1, 10, 2),\n",
       "                         'n_estimators': range(90, 150, 10)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "278ff28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 0.1,\n",
       " 'learning_rate': 0.14,\n",
       " 'max_depth': 3,\n",
       " 'min_child_weight': 3,\n",
       " 'n_estimators': 140}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "76929a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best_para = xgb_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9cb1d9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0.1, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.14, max_delta_step=0, max_depth=3,\n",
       "             min_child_weight=3, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=140, n_jobs=8, num_parallel_tree=1,\n",
       "             objective='reg:squarederror', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "             validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_regression = XGBRegressor(\n",
    "                    learning_rate = xgb_best_para[\"learning_rate\"],\n",
    "                    max_depth = xgb_best_para[\"max_depth\"],\n",
    "                    n_estimators = xgb_best_para[\"n_estimators\"],\n",
    "                    gamma = xgb_best_para[\"gamma\"],\n",
    "                    min_child_weight = xgb_best_para[\"min_child_weight\"]\n",
    "                    )\n",
    "xgb_regression.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b4ef0d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_file = 'xgb_model.sav'\n",
    "pickle.dump(xgb_regression , open(model_path+xgb_file , \"wb\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc70110f",
   "metadata": {},
   "source": [
    "## 7. ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f91a2a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(tf.keras.Input(shape=x_train.shape[1]))\n",
    "    \n",
    "    for i in range(hp.Int('layers', 2, 15)):\n",
    "        model.add(layers.Dense(units=hp.Int('units_' + str(i),\n",
    "                                            min_value=3,\n",
    "                                            max_value=15,\n",
    "                                            step=1),\n",
    "                               activation=hp.Choice('act_' + str(i),[\"relu\",\"tanh\"])))\n",
    "        \n",
    "    model.add(layers.Dense(1, activation='linear'))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
    "        loss='mean_squared_error',\n",
    "        metrics=['mean_squared_error'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ff70014c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_mean_squared_error',\n",
    "    max_trials=50,\n",
    "    executions_per_trial=3,\n",
    "    project_name = \"ANN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ee299d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 6\n",
      "layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 15, 'step': 1, 'sampling': None}\n",
      "units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 3, 'max_value': 15, 'step': 1, 'sampling': None}\n",
      "act_0 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh'], 'ordered': False}\n",
      "units_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 3, 'max_value': 15, 'step': 1, 'sampling': None}\n",
      "act_1 (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh'], 'ordered': False}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7f76214b",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c5e0a487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 Complete [00h 00m 09s]\n",
      "val_mean_squared_error: 365447.34375\n",
      "\n",
      "Best val_mean_squared_error So Far: 3672.2986653645835\n",
      "Total elapsed time: 00h 09m 09s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(x_train, y_train.values,\n",
    "             epochs=100,\n",
    "             validation_split = 0.20,\n",
    "             callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c1975b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in .\\ANN\n",
      "Showing 10 best trials\n",
      "Objective(name='val_mean_squared_error', direction='min')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 4\n",
      "units_0: 10\n",
      "act_0: tanh\n",
      "units_1: 8\n",
      "act_1: relu\n",
      "learning_rate: 0.01\n",
      "units_2: 8\n",
      "act_2: relu\n",
      "units_3: 13\n",
      "act_3: relu\n",
      "units_4: 8\n",
      "act_4: tanh\n",
      "units_5: 13\n",
      "act_5: relu\n",
      "units_6: 3\n",
      "act_6: relu\n",
      "units_7: 13\n",
      "act_7: tanh\n",
      "units_8: 11\n",
      "act_8: tanh\n",
      "units_9: 9\n",
      "act_9: tanh\n",
      "units_10: 8\n",
      "act_10: relu\n",
      "units_11: 8\n",
      "act_11: tanh\n",
      "units_12: 13\n",
      "act_12: relu\n",
      "units_13: 6\n",
      "act_13: relu\n",
      "units_14: 3\n",
      "act_14: relu\n",
      "Score: 3672.2986653645835\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 13\n",
      "units_0: 3\n",
      "act_0: tanh\n",
      "units_1: 7\n",
      "act_1: tanh\n",
      "learning_rate: 0.001\n",
      "units_2: 15\n",
      "act_2: relu\n",
      "units_3: 12\n",
      "act_3: tanh\n",
      "units_4: 8\n",
      "act_4: relu\n",
      "units_5: 13\n",
      "act_5: relu\n",
      "units_6: 10\n",
      "act_6: tanh\n",
      "units_7: 8\n",
      "act_7: tanh\n",
      "units_8: 10\n",
      "act_8: relu\n",
      "units_9: 13\n",
      "act_9: relu\n",
      "units_10: 13\n",
      "act_10: relu\n",
      "units_11: 11\n",
      "act_11: relu\n",
      "units_12: 15\n",
      "act_12: relu\n",
      "units_13: 12\n",
      "act_13: tanh\n",
      "units_14: 13\n",
      "act_14: tanh\n",
      "Score: 5269.94580078125\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 3\n",
      "units_0: 3\n",
      "act_0: relu\n",
      "units_1: 12\n",
      "act_1: relu\n",
      "learning_rate: 0.01\n",
      "units_2: 11\n",
      "act_2: relu\n",
      "units_3: 9\n",
      "act_3: tanh\n",
      "units_4: 10\n",
      "act_4: tanh\n",
      "units_5: 7\n",
      "act_5: tanh\n",
      "units_6: 12\n",
      "act_6: tanh\n",
      "units_7: 6\n",
      "act_7: tanh\n",
      "units_8: 15\n",
      "act_8: tanh\n",
      "units_9: 9\n",
      "act_9: relu\n",
      "units_10: 6\n",
      "act_10: relu\n",
      "units_11: 11\n",
      "act_11: tanh\n",
      "units_12: 15\n",
      "act_12: tanh\n",
      "units_13: 14\n",
      "act_13: tanh\n",
      "units_14: 10\n",
      "act_14: relu\n",
      "Score: 6081.6689453125\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 4\n",
      "units_0: 3\n",
      "act_0: tanh\n",
      "units_1: 3\n",
      "act_1: tanh\n",
      "learning_rate: 0.01\n",
      "units_2: 6\n",
      "act_2: relu\n",
      "units_3: 12\n",
      "act_3: relu\n",
      "units_4: 14\n",
      "act_4: tanh\n",
      "units_5: 12\n",
      "act_5: tanh\n",
      "units_6: 7\n",
      "act_6: tanh\n",
      "units_7: 12\n",
      "act_7: tanh\n",
      "units_8: 4\n",
      "act_8: relu\n",
      "units_9: 7\n",
      "act_9: relu\n",
      "units_10: 10\n",
      "act_10: tanh\n",
      "units_11: 10\n",
      "act_11: tanh\n",
      "units_12: 5\n",
      "act_12: relu\n",
      "units_13: 5\n",
      "act_13: relu\n",
      "units_14: 5\n",
      "act_14: tanh\n",
      "Score: 6831.14013671875\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 3\n",
      "units_0: 7\n",
      "act_0: tanh\n",
      "units_1: 14\n",
      "act_1: relu\n",
      "learning_rate: 0.01\n",
      "units_2: 4\n",
      "act_2: relu\n",
      "units_3: 9\n",
      "act_3: tanh\n",
      "units_4: 12\n",
      "act_4: relu\n",
      "units_5: 6\n",
      "act_5: relu\n",
      "units_6: 3\n",
      "act_6: tanh\n",
      "units_7: 10\n",
      "act_7: tanh\n",
      "units_8: 5\n",
      "act_8: tanh\n",
      "units_9: 14\n",
      "act_9: tanh\n",
      "units_10: 5\n",
      "act_10: tanh\n",
      "units_11: 7\n",
      "act_11: relu\n",
      "units_12: 10\n",
      "act_12: tanh\n",
      "units_13: 14\n",
      "act_13: tanh\n",
      "units_14: 12\n",
      "act_14: relu\n",
      "Score: 7538.69091796875\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 8\n",
      "units_0: 8\n",
      "act_0: tanh\n",
      "units_1: 9\n",
      "act_1: relu\n",
      "learning_rate: 0.01\n",
      "units_2: 12\n",
      "act_2: tanh\n",
      "units_3: 11\n",
      "act_3: relu\n",
      "units_4: 11\n",
      "act_4: tanh\n",
      "units_5: 11\n",
      "act_5: tanh\n",
      "units_6: 4\n",
      "act_6: relu\n",
      "units_7: 14\n",
      "act_7: relu\n",
      "units_8: 4\n",
      "act_8: relu\n",
      "units_9: 5\n",
      "act_9: tanh\n",
      "units_10: 13\n",
      "act_10: relu\n",
      "units_11: 10\n",
      "act_11: relu\n",
      "units_12: 9\n",
      "act_12: relu\n",
      "units_13: 12\n",
      "act_13: relu\n",
      "units_14: 8\n",
      "act_14: tanh\n",
      "Score: 17527.360188802082\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 8\n",
      "units_0: 15\n",
      "act_0: relu\n",
      "units_1: 10\n",
      "act_1: tanh\n",
      "learning_rate: 0.01\n",
      "units_2: 12\n",
      "act_2: relu\n",
      "units_3: 11\n",
      "act_3: tanh\n",
      "units_4: 9\n",
      "act_4: tanh\n",
      "units_5: 13\n",
      "act_5: relu\n",
      "units_6: 9\n",
      "act_6: relu\n",
      "units_7: 13\n",
      "act_7: relu\n",
      "units_8: 6\n",
      "act_8: relu\n",
      "units_9: 8\n",
      "act_9: relu\n",
      "units_10: 13\n",
      "act_10: relu\n",
      "units_11: 12\n",
      "act_11: tanh\n",
      "units_12: 13\n",
      "act_12: tanh\n",
      "units_13: 6\n",
      "act_13: relu\n",
      "units_14: 10\n",
      "act_14: relu\n",
      "Score: 29656.404296875\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 7\n",
      "units_0: 6\n",
      "act_0: relu\n",
      "units_1: 11\n",
      "act_1: relu\n",
      "learning_rate: 0.01\n",
      "units_2: 11\n",
      "act_2: relu\n",
      "units_3: 14\n",
      "act_3: relu\n",
      "units_4: 10\n",
      "act_4: tanh\n",
      "units_5: 15\n",
      "act_5: tanh\n",
      "units_6: 9\n",
      "act_6: relu\n",
      "units_7: 8\n",
      "act_7: tanh\n",
      "units_8: 12\n",
      "act_8: relu\n",
      "units_9: 12\n",
      "act_9: tanh\n",
      "units_10: 14\n",
      "act_10: tanh\n",
      "units_11: 13\n",
      "act_11: tanh\n",
      "units_12: 8\n",
      "act_12: relu\n",
      "units_13: 10\n",
      "act_13: tanh\n",
      "units_14: 8\n",
      "act_14: relu\n",
      "Score: 33967.876627604164\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 6\n",
      "units_0: 5\n",
      "act_0: tanh\n",
      "units_1: 15\n",
      "act_1: tanh\n",
      "learning_rate: 0.01\n",
      "units_2: 6\n",
      "act_2: tanh\n",
      "units_3: 14\n",
      "act_3: tanh\n",
      "units_4: 13\n",
      "act_4: tanh\n",
      "units_5: 4\n",
      "act_5: relu\n",
      "units_6: 15\n",
      "act_6: relu\n",
      "units_7: 8\n",
      "act_7: relu\n",
      "units_8: 13\n",
      "act_8: tanh\n",
      "units_9: 7\n",
      "act_9: relu\n",
      "units_10: 10\n",
      "act_10: relu\n",
      "units_11: 8\n",
      "act_11: relu\n",
      "units_12: 11\n",
      "act_12: tanh\n",
      "units_13: 4\n",
      "act_13: tanh\n",
      "units_14: 8\n",
      "act_14: tanh\n",
      "Score: 43687.84765625\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "layers: 14\n",
      "units_0: 7\n",
      "act_0: tanh\n",
      "units_1: 13\n",
      "act_1: relu\n",
      "learning_rate: 0.01\n",
      "units_2: 11\n",
      "act_2: tanh\n",
      "units_3: 3\n",
      "act_3: tanh\n",
      "units_4: 8\n",
      "act_4: tanh\n",
      "units_5: 9\n",
      "act_5: tanh\n",
      "units_6: 11\n",
      "act_6: relu\n",
      "units_7: 6\n",
      "act_7: tanh\n",
      "units_8: 4\n",
      "act_8: relu\n",
      "units_9: 10\n",
      "act_9: tanh\n",
      "units_10: 13\n",
      "act_10: relu\n",
      "units_11: 15\n",
      "act_11: relu\n",
      "units_12: 10\n",
      "act_12: relu\n",
      "units_13: 10\n",
      "act_13: relu\n",
      "Score: 43857.505208333336\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1e653f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 10)                110       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 88        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 13)                117       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 14        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 401\n",
      "Trainable params: 401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "'''This link has proved that while showing summary of result number of unit shows higher than \n",
    "    actual number of layers which reported as bug in official keras documents.\n",
    "    However it has been proven that finalized model description can be obtained by following.\n",
    "    Use number of layer shown as number_layer arguments [i.g best model with number_layer = 4\n",
    "    units_0 to units_3 in our case. Avoid higher values.]\n",
    "    \n",
    "    https://github.com/keras-team/keras-tuner/issues/66#issuecomment-525923517'''\n",
    "tuner.get_best_models()[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c50b540e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_best_para = tuner.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7686141b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_regression = Sequential()\n",
    "\n",
    "\n",
    "#Input layer \n",
    "ann_regression.add(tf.keras.Input(shape=x_train.shape[1]))\n",
    "\n",
    "limit = ann_best_para[\"layers\"] \n",
    "\n",
    "#Number of hidden layer\n",
    "for i in range(0, limit) :\n",
    "    ann_regression.add(Dense(units=ann_best_para['units_'+str(i)],activation=ann_best_para['act_'+str(i)]))\n",
    "\n",
    "    \n",
    "#Last Output Layer\n",
    "ann_regression.add(Dense(units=1,activation='linear'))\n",
    "\n",
    "\n",
    "\n",
    "#ANN compilation with loss function and optimization\n",
    "ann_regression.compile(loss='mse', optimizer=keras.optimizers.Adam(learning_rate=ann_best_para['learning_rate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0081ec22",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop_final = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b3bf2497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 362600.9062 - val_loss: 365856.3750\n",
      "Epoch 2/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 361595.0625 - val_loss: 364463.5938\n",
      "Epoch 3/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 359746.2812 - val_loss: 361743.2500\n",
      "Epoch 4/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 356208.6562 - val_loss: 356330.6562\n",
      "Epoch 5/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 349427.7500 - val_loss: 346224.4688\n",
      "Epoch 6/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 336772.9688 - val_loss: 327949.5312\n",
      "Epoch 7/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 314827.4375 - val_loss: 295470.7812\n",
      "Epoch 8/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 277640.4062 - val_loss: 244476.0000\n",
      "Epoch 9/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 220506.1250 - val_loss: 172110.8594\n",
      "Epoch 10/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 146832.4531 - val_loss: 88503.5781\n",
      "Epoch 11/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 69385.1641 - val_loss: 31771.8828\n",
      "Epoch 12/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 35167.5000 - val_loss: 35590.2344\n",
      "Epoch 13/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 47164.3945 - val_loss: 33441.3008\n",
      "Epoch 14/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 35539.1055 - val_loss: 18772.9492\n",
      "Epoch 15/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 24578.8184 - val_loss: 18440.3691\n",
      "Epoch 16/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 23629.9258 - val_loss: 17904.5137\n",
      "Epoch 17/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 21338.2891 - val_loss: 14728.6436\n",
      "Epoch 18/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 17573.7969 - val_loss: 12286.6045\n",
      "Epoch 19/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 16028.8740 - val_loss: 11885.7441\n",
      "Epoch 20/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 14741.3301 - val_loss: 10439.3672\n",
      "Epoch 21/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 12251.3262 - val_loss: 9195.2891\n",
      "Epoch 22/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 10719.4170 - val_loss: 8855.8047\n",
      "Epoch 23/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 9896.9365 - val_loss: 8145.3657\n",
      "Epoch 24/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8628.7363 - val_loss: 7299.1582\n",
      "Epoch 25/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7996.0225 - val_loss: 6997.8071\n",
      "Epoch 26/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7564.6685 - val_loss: 6611.3462\n",
      "Epoch 27/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7069.2227 - val_loss: 6423.5898\n",
      "Epoch 28/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6834.5488 - val_loss: 6344.9023\n",
      "Epoch 29/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6561.2998 - val_loss: 6216.7148\n",
      "Epoch 30/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6275.8589 - val_loss: 6196.0396\n",
      "Epoch 31/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6107.5830 - val_loss: 6203.5845\n",
      "Epoch 32/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5974.8257 - val_loss: 6041.4570\n",
      "Epoch 33/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5825.7329 - val_loss: 5969.3477\n",
      "Epoch 34/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 5752.1382 - val_loss: 6051.6357\n",
      "Epoch 35/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5638.5713 - val_loss: 5726.7173\n",
      "Epoch 36/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5320.5806 - val_loss: 5650.8901\n",
      "Epoch 37/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5182.5908 - val_loss: 5557.2871\n",
      "Epoch 38/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4480.5181 - val_loss: 5491.1216\n",
      "Epoch 39/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4384.3838 - val_loss: 5562.9805\n",
      "Epoch 40/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4197.8130 - val_loss: 5204.7700\n",
      "Epoch 41/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3964.8301 - val_loss: 5125.4165\n",
      "Epoch 42/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3742.5037 - val_loss: 5420.0898\n",
      "Epoch 43/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3507.7512 - val_loss: 5553.1523\n",
      "Epoch 44/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3330.6299 - val_loss: 5415.5581\n",
      "Epoch 45/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3071.7354 - val_loss: 5250.6436\n",
      "Epoch 46/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2538.9285 - val_loss: 5182.1553\n",
      "Epoch 47/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2272.2415 - val_loss: 5239.0474\n",
      "Epoch 48/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2147.3948 - val_loss: 5124.5376\n",
      "Epoch 49/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2054.2986 - val_loss: 4953.5039\n",
      "Epoch 50/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2078.4231 - val_loss: 4617.6289\n",
      "Epoch 51/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2080.6714 - val_loss: 4401.0322\n",
      "Epoch 52/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1858.8043 - val_loss: 4419.3091\n",
      "Epoch 53/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1792.2072 - val_loss: 4539.2969\n",
      "Epoch 54/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1782.9722 - val_loss: 4445.2710\n",
      "Epoch 55/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1699.7133 - val_loss: 4228.8579\n",
      "Epoch 56/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1641.2374 - val_loss: 4082.5605\n",
      "Epoch 57/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1668.2537 - val_loss: 3999.8098\n",
      "Epoch 58/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1581.6011 - val_loss: 3996.9849\n",
      "Epoch 59/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1549.8724 - val_loss: 4123.0195\n",
      "Epoch 60/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1536.3905 - val_loss: 3997.4834\n",
      "Epoch 61/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1481.4130 - val_loss: 3856.7786\n",
      "Epoch 62/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1476.2477 - val_loss: 3670.9919\n",
      "Epoch 63/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1458.1096 - val_loss: 3534.0725\n",
      "Epoch 64/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1425.9199 - val_loss: 3570.4541\n",
      "Epoch 65/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1335.6980 - val_loss: 3523.3411\n",
      "Epoch 66/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1314.7301 - val_loss: 3486.9844\n",
      "Epoch 67/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1282.1478 - val_loss: 3441.8274\n",
      "Epoch 68/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1284.3185 - val_loss: 3302.3701\n",
      "Epoch 69/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1248.3906 - val_loss: 3329.5464\n",
      "Epoch 70/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1228.1947 - val_loss: 3295.5730\n",
      "Epoch 71/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1202.0399 - val_loss: 3256.8823\n",
      "Epoch 72/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1248.1163 - val_loss: 3122.8828\n",
      "Epoch 73/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1156.4287 - val_loss: 3174.1616\n",
      "Epoch 74/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1168.1083 - val_loss: 3217.4717\n",
      "Epoch 75/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1142.0033 - val_loss: 3211.5793\n",
      "Epoch 76/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1118.0752 - val_loss: 3171.8357\n",
      "Epoch 77/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1085.6581 - val_loss: 3050.0393\n",
      "Epoch 78/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 1095.7640 - val_loss: 3020.1838\n",
      "Epoch 79/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1066.4552 - val_loss: 2990.1118\n",
      "Epoch 80/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1074.8092 - val_loss: 2922.6992\n",
      "Epoch 81/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1000.3409 - val_loss: 2780.4880\n",
      "Epoch 82/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1022.4380 - val_loss: 2750.0718\n",
      "Epoch 83/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 980.6738 - val_loss: 2847.9316\n",
      "Epoch 84/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 974.9414 - val_loss: 2827.9160\n",
      "Epoch 85/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 964.2953 - val_loss: 2744.8247\n",
      "Epoch 86/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 941.0888 - val_loss: 2685.1956\n",
      "Epoch 87/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 931.0502 - val_loss: 2653.5610\n",
      "Epoch 88/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 918.2505 - val_loss: 2705.4375\n",
      "Epoch 89/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 920.8309 - val_loss: 2629.8215\n",
      "Epoch 90/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 876.7204 - val_loss: 2598.4106\n",
      "Epoch 91/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 917.3184 - val_loss: 2490.3303\n",
      "Epoch 92/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 893.2382 - val_loss: 2536.2637\n",
      "Epoch 93/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 887.2167 - val_loss: 2692.8574\n",
      "Epoch 94/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 876.3682 - val_loss: 2572.3271\n",
      "Epoch 95/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 859.5059 - val_loss: 2412.4612\n",
      "Epoch 96/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 806.8801 - val_loss: 2493.6621\n",
      "Epoch 97/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 818.2018 - val_loss: 2520.2957\n",
      "Epoch 98/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 793.6635 - val_loss: 2408.0261\n",
      "Epoch 99/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 778.1304 - val_loss: 2390.9453\n",
      "Epoch 100/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 766.0096 - val_loss: 2293.3147\n",
      "Epoch 101/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 759.2908 - val_loss: 2351.2793\n",
      "Epoch 102/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 750.1716 - val_loss: 2470.1755\n",
      "Epoch 103/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 719.9039 - val_loss: 2270.4456\n",
      "Epoch 104/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 715.9070 - val_loss: 2215.7983\n",
      "Epoch 105/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 693.9398 - val_loss: 2260.1384\n",
      "Epoch 106/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 705.5123 - val_loss: 2340.1267\n",
      "Epoch 107/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 713.5881 - val_loss: 2191.7080\n",
      "Epoch 108/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 663.6333 - val_loss: 2029.3812\n",
      "Epoch 109/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 668.2421 - val_loss: 1994.9506\n",
      "Epoch 110/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 649.8926 - val_loss: 2138.7480\n",
      "Epoch 111/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 620.7926 - val_loss: 2088.4058\n",
      "Epoch 112/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 612.7117 - val_loss: 2024.0125\n",
      "Epoch 113/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 601.3586 - val_loss: 1983.5398\n",
      "Epoch 114/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 626.9000 - val_loss: 1927.8683\n",
      "Epoch 115/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 579.2379 - val_loss: 1842.0353\n",
      "Epoch 116/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 582.9513 - val_loss: 1798.7306\n",
      "Epoch 117/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 546.4820 - val_loss: 1661.6871\n",
      "Epoch 118/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 540.6538 - val_loss: 1743.9786\n",
      "Epoch 119/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 525.8406 - val_loss: 1749.2657\n",
      "Epoch 120/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 507.3631 - val_loss: 1622.7472\n",
      "Epoch 121/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 522.8606 - val_loss: 1555.8330\n",
      "Epoch 122/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 501.3084 - val_loss: 1498.6913\n",
      "Epoch 123/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 479.0075 - val_loss: 1572.5148\n",
      "Epoch 124/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 491.2134 - val_loss: 1531.2968\n",
      "Epoch 125/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 474.3557 - val_loss: 1455.5107\n",
      "Epoch 126/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 475.7393 - val_loss: 1479.4977\n",
      "Epoch 127/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 459.0650 - val_loss: 1637.5258\n",
      "Epoch 128/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 464.3757 - val_loss: 1506.2134\n",
      "Epoch 129/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 455.0422 - val_loss: 1452.0588\n",
      "Epoch 130/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 448.6149 - val_loss: 1438.3700\n",
      "Epoch 131/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 441.9920 - val_loss: 1338.3829\n",
      "Epoch 132/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 415.1684 - val_loss: 1453.1859\n",
      "Epoch 133/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 436.6023 - val_loss: 1343.6047\n",
      "Epoch 134/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 418.3563 - val_loss: 1238.8195\n",
      "Epoch 135/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 424.0569 - val_loss: 1354.8115\n",
      "Epoch 136/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 424.6677 - val_loss: 1231.9733\n",
      "Epoch 137/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 418.0463 - val_loss: 1149.8193\n",
      "Epoch 138/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 399.5135 - val_loss: 1280.0793\n",
      "Epoch 139/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 390.6355 - val_loss: 1253.8463\n",
      "Epoch 140/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 384.7003 - val_loss: 1128.3956\n",
      "Epoch 141/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 381.0744 - val_loss: 1169.4807\n",
      "Epoch 142/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 377.6115 - val_loss: 1210.7056\n",
      "Epoch 143/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 377.4175 - val_loss: 1228.3291\n",
      "Epoch 144/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 395.9322 - val_loss: 1262.9812\n",
      "Epoch 145/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 369.4024 - val_loss: 1238.1158\n",
      "Epoch 146/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 369.3068 - val_loss: 1111.0585\n",
      "Epoch 147/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 381.3633 - val_loss: 1149.2620\n",
      "Epoch 148/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 367.7345 - val_loss: 1257.7354\n",
      "Epoch 149/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 369.7316 - val_loss: 1059.5310\n",
      "Epoch 150/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 362.5884 - val_loss: 1115.5034\n",
      "Epoch 151/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 354.6878 - val_loss: 1217.5198\n",
      "Epoch 152/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 348.9276 - val_loss: 1131.4954\n",
      "Epoch 153/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 339.6736 - val_loss: 1176.7881\n",
      "Epoch 154/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 341.9576 - val_loss: 1162.7762\n",
      "Epoch 155/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 330.7855 - val_loss: 1031.1748\n",
      "Epoch 156/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - loss: 348.8412 - val_loss: 943.2906\n",
      "Epoch 157/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 345.0706 - val_loss: 1014.3139\n",
      "Epoch 158/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 339.1528 - val_loss: 991.7064\n",
      "Epoch 159/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 336.8478 - val_loss: 1035.2302\n",
      "Epoch 160/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 320.3034 - val_loss: 1042.7109\n",
      "Epoch 161/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 353.1299 - val_loss: 1034.7227\n",
      "Epoch 162/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 346.4420 - val_loss: 1081.6376\n",
      "Epoch 163/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 310.0940 - val_loss: 1028.3955\n",
      "Epoch 164/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 328.2421 - val_loss: 1008.8324\n",
      "Epoch 165/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 311.6298 - val_loss: 915.2078\n",
      "Epoch 166/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 310.1292 - val_loss: 1010.5612\n",
      "Epoch 167/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 315.8505 - val_loss: 1014.3672\n",
      "Epoch 168/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 301.6676 - val_loss: 1044.0211\n",
      "Epoch 169/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 306.1835 - val_loss: 916.5577\n",
      "Epoch 170/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 306.3864 - val_loss: 966.1960\n",
      "Epoch 171/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 316.9984 - val_loss: 917.9839\n",
      "Epoch 172/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 285.1899 - val_loss: 963.7425\n",
      "Epoch 173/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 287.8617 - val_loss: 935.4370\n",
      "Epoch 174/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 285.6257 - val_loss: 945.3457\n",
      "Epoch 175/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 300.4235 - val_loss: 899.8349\n",
      "Epoch 176/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 321.8950 - val_loss: 741.7962\n",
      "Epoch 177/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 309.1439 - val_loss: 870.2099\n",
      "Epoch 178/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 315.4371 - val_loss: 857.2476\n",
      "Epoch 179/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 274.4690 - val_loss: 1094.4813\n",
      "Epoch 180/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 288.3011 - val_loss: 924.7866\n",
      "Epoch 181/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 269.5948 - val_loss: 860.4459\n",
      "Epoch 182/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 272.6122 - val_loss: 866.2986\n",
      "Epoch 183/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 277.6110 - val_loss: 919.7985\n",
      "Epoch 184/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 258.3417 - val_loss: 960.1801\n",
      "Epoch 185/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 262.7902 - val_loss: 898.5551\n",
      "Epoch 186/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 259.5344 - val_loss: 883.5351\n",
      "Epoch 187/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 249.2303 - val_loss: 917.9234\n",
      "Epoch 188/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 256.0224 - val_loss: 918.1044\n",
      "Epoch 189/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 247.2001 - val_loss: 931.7480\n",
      "Epoch 190/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 241.5409 - val_loss: 851.0638\n",
      "Epoch 191/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 260.0446 - val_loss: 861.3154\n",
      "Epoch 192/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 233.9096 - val_loss: 945.6047\n",
      "Epoch 193/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 237.2519 - val_loss: 893.6570\n",
      "Epoch 194/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 233.4531 - val_loss: 896.1863\n",
      "Epoch 195/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 253.3935 - val_loss: 887.5271\n",
      "Epoch 196/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 244.6862 - val_loss: 873.4285\n",
      "Epoch 197/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 228.0126 - val_loss: 886.2004\n",
      "Epoch 198/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 242.3289 - val_loss: 905.5043\n",
      "Epoch 199/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 237.7243 - val_loss: 857.2134\n",
      "Epoch 200/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 219.3262 - val_loss: 1051.8756\n",
      "Epoch 201/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 262.9611 - val_loss: 859.1409\n",
      "Epoch 202/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 235.2802 - val_loss: 948.9690\n",
      "Epoch 203/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 273.8022 - val_loss: 1070.1967\n",
      "Epoch 204/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 263.1943 - val_loss: 1058.0188\n",
      "Epoch 205/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 239.3764 - val_loss: 938.6022\n",
      "Epoch 206/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 234.2444 - val_loss: 810.0828\n",
      "Epoch 207/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 231.9771 - val_loss: 870.6724\n",
      "Epoch 208/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 210.3298 - val_loss: 878.6914\n",
      "Epoch 209/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 221.5887 - val_loss: 864.6432\n",
      "Epoch 210/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 212.8700 - val_loss: 916.7654\n",
      "Epoch 211/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 215.8160 - val_loss: 1056.3322\n",
      "Epoch 212/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 216.4603 - val_loss: 916.8999\n",
      "Epoch 213/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 198.7965 - val_loss: 828.6637\n",
      "Epoch 214/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 208.0544 - val_loss: 824.7418\n",
      "Epoch 215/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 200.3184 - val_loss: 912.5208\n",
      "Epoch 216/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 188.8367 - val_loss: 940.1841\n",
      "Epoch 217/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 193.9301 - val_loss: 964.2493\n",
      "Epoch 218/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 194.6531 - val_loss: 1094.7297\n",
      "Epoch 219/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 217.6920 - val_loss: 985.9196\n",
      "Epoch 220/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 202.6075 - val_loss: 876.5915\n",
      "Epoch 221/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 192.4128 - val_loss: 899.0586\n",
      "Epoch 222/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 203.5051 - val_loss: 852.3982\n",
      "Epoch 223/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 204.5157 - val_loss: 858.3179\n",
      "Epoch 224/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 194.9880 - val_loss: 897.7148\n",
      "Epoch 225/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 180.2884 - val_loss: 867.5316\n",
      "Epoch 226/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 183.5765 - val_loss: 958.8807\n",
      "Epoch 227/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 188.4407 - val_loss: 887.4653\n",
      "Epoch 228/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 174.7272 - val_loss: 917.7046\n",
      "Epoch 229/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 170.2998 - val_loss: 910.4440\n",
      "Epoch 230/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 177.2350 - val_loss: 857.9749\n",
      "Epoch 231/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 177.7569 - val_loss: 826.7538\n",
      "Epoch 232/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 172.1069 - val_loss: 953.9170\n",
      "Epoch 233/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 173.6431 - val_loss: 884.1813\n",
      "Epoch 234/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 167.3737 - val_loss: 938.6840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 235/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 172.2152 - val_loss: 848.8588\n",
      "Epoch 236/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 176.2249 - val_loss: 862.1077\n",
      "Epoch 237/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 163.7327 - val_loss: 1001.7184\n",
      "Epoch 238/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 173.1095 - val_loss: 956.5935\n",
      "Epoch 239/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 180.3757 - val_loss: 972.8777\n",
      "Epoch 240/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 163.4874 - val_loss: 869.9030\n",
      "Epoch 241/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 159.4633 - val_loss: 881.5170\n",
      "Epoch 242/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 185.3103 - val_loss: 840.2098\n",
      "Epoch 243/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 203.2511 - val_loss: 889.9073\n",
      "Epoch 244/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 183.6826 - val_loss: 978.9227\n",
      "Epoch 245/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 167.4091 - val_loss: 940.9661\n",
      "Epoch 246/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 197.5388 - val_loss: 987.6567\n",
      "Epoch 247/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 184.5294 - val_loss: 834.0018\n",
      "Epoch 248/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 191.2314 - val_loss: 912.0148\n",
      "Epoch 249/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 181.9055 - val_loss: 969.4220\n",
      "Epoch 250/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 275.1137 - val_loss: 1205.6278\n",
      "Epoch 251/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 207.3388 - val_loss: 912.7826\n",
      "Epoch 252/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 176.4287 - val_loss: 876.3704\n",
      "Epoch 253/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 228.6371 - val_loss: 775.2510\n",
      "Epoch 254/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 200.9504 - val_loss: 945.9956\n",
      "Epoch 255/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 187.5706 - val_loss: 1023.5193\n",
      "Epoch 256/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 194.9985 - val_loss: 939.8100\n",
      "Epoch 257/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 180.7777 - val_loss: 954.5428\n",
      "Epoch 258/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 180.8070 - val_loss: 942.4198\n",
      "Epoch 259/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 186.5563 - val_loss: 1037.6255\n",
      "Epoch 260/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 182.2985 - val_loss: 1025.2633\n",
      "Epoch 261/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 166.6363 - val_loss: 989.8234\n",
      "Epoch 262/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 171.9339 - val_loss: 880.8882\n",
      "Epoch 263/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 178.9009 - val_loss: 876.2418\n",
      "Epoch 264/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 163.9523 - val_loss: 1035.8574\n",
      "Epoch 265/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 162.4282 - val_loss: 939.4380\n",
      "Epoch 266/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 174.7658 - val_loss: 970.0604\n",
      "Epoch 267/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 171.7112 - val_loss: 867.7066\n",
      "Epoch 268/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 150.0776 - val_loss: 957.2841\n",
      "Epoch 269/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 163.9044 - val_loss: 863.3283\n",
      "Epoch 270/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 161.6096 - val_loss: 909.2056\n",
      "Epoch 271/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 174.6881 - val_loss: 929.9686\n",
      "Epoch 272/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 153.2298 - val_loss: 975.5106\n",
      "Epoch 273/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 148.6088 - val_loss: 858.1970\n",
      "Epoch 274/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 193.6752 - val_loss: 855.4962\n",
      "Epoch 275/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 210.8017 - val_loss: 993.2571\n",
      "Epoch 276/1000\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 162.3528 - val_loss: 767.3961\n",
      "Epoch 00276: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ec8d2af640>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_regression.fit(x=x_train, \n",
    "          y=y_train, \n",
    "          epochs=1000,\n",
    "          validation_split=0.20, \n",
    "          verbose=1,\n",
    "          callbacks=[early_stop_final],\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "39a84960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>362600.906250</td>\n",
       "      <td>365856.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>361595.062500</td>\n",
       "      <td>364463.593750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>359746.281250</td>\n",
       "      <td>361743.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>356208.656250</td>\n",
       "      <td>356330.656250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>349427.750000</td>\n",
       "      <td>346224.468750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>153.229828</td>\n",
       "      <td>975.510559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>148.608765</td>\n",
       "      <td>858.196960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>193.675201</td>\n",
       "      <td>855.496216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>210.801682</td>\n",
       "      <td>993.257141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>162.352814</td>\n",
       "      <td>767.396057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>276 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              loss       val_loss\n",
       "0    362600.906250  365856.375000\n",
       "1    361595.062500  364463.593750\n",
       "2    359746.281250  361743.250000\n",
       "3    356208.656250  356330.656250\n",
       "4    349427.750000  346224.468750\n",
       "..             ...            ...\n",
       "271     153.229828     975.510559\n",
       "272     148.608765     858.196960\n",
       "273     193.675201     855.496216\n",
       "274     210.801682     993.257141\n",
       "275     162.352814     767.396057\n",
       "\n",
       "[276 rows x 2 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(ann_regression.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c66b46e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ann_regression_df = pd.DataFrame(ann_regression.history.history)\n",
    "ann_regression_df[[\"loss\",\"val_loss\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d3f7a3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 8)                 88        \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 13)                117       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 14        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 401\n",
      "Trainable params: 401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ann_regression.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a6b184ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 798us/step - loss: 277.4771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "277.4771423339844"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_regression.evaluate(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4e7cc152",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_regression_df.to_csv(export_data_path+\"LOSS_VALUES.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "91f7c24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_file = 'ann_model.h5'\n",
    "ann_regression.save(model_path+ann_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817f44e3",
   "metadata": {},
   "source": [
    ".......................................THE END.........................................................."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2739cf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96c5ace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
